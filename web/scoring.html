<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>LegacyCodeBench | Scoring</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <link rel="stylesheet" href="assets/styles.css">
</head>

<body>
  <header>
    <div class="container"
      style="display:flex;justify-content:space-between;align-items:center;padding:1.25rem 1.25rem 1rem;">
      <div class="logo">LegacyCodeBench</div>
      <nav aria-label="Primary">
        <a href="index.html">Overview</a>
        <a href="leaderboard.html">Leaderboard</a>
        <a href="datasets.html">Datasets</a>
        <a href="scoring.html" class="active">Scoring</a>
        <a href="docs.html">Docs</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="hero" aria-labelledby="scoring-title">
      <h1 id="scoring-title">Scoring Methodology v2.0</h1>
      <p>LegacyCodeBench v2.0 uses a ground-truth based evaluation approach. AI-generated documentation is validated
        against source code elements extracted via static analysis, not human-written references.</p>
      <p class="table-hint">All scores are deterministic and reproducible. The primary metric is LCB Score, a weighted
        composite of four components.</p>
    </section>

    <section aria-labelledby="lcb-score">
      <h2 class="section-title" id="lcb-score">LCB Score Formula</h2>
      <div class="formula" style="font-size: 16px; padding: 24px;">
        LCB Score = (0.35 × BF) + (0.30 × SC) + (0.25 × SQ) + (0.10 × TR)
      </div>
      <p class="table-hint">Scores range from 0-100. Higher is better.</p>
    </section>

    <section aria-labelledby="components">
      <h2 class="section-title" id="components">Evaluation Components</h2>
      <div class="grid grid-2">
        <div class="card">
          <h3>Behavioral Fidelity (BF) — 35%</h3>
          <p>Execution-based testing. Can code be regenerated from docs and produce matching outputs?</p>
          <ul class="list-muted">
            <li>Generate test cases from ground truth</li>
            <li>Execute original COBOL with test inputs</li>
            <li>Generate COBOL from documentation</li>
            <li>Compare outputs for behavioral match</li>
          </ul>
          <p class="table-hint">Requires Docker with GnuCOBOL for execution.</p>
        </div>
        <div class="card">
          <h3>Structural Completeness (SC) — 30%</h3>
          <p>Element coverage vs auto-extracted ground truth from source code.</p>
          <ul class="list-muted">
            <li>Data structures documented</li>
            <li>Paragraphs/sections covered</li>
            <li>Business rules captured</li>
            <li>File dependencies mentioned</li>
          </ul>
          <p class="table-hint">Ground truth extracted via static analysis (95%+ automated).</p>
        </div>
        <div class="card">
          <h3>Semantic Quality (SQ) — 25%</h3>
          <p>LLM-as-judge evaluation of documentation quality.</p>
          <ul class="list-muted">
            <li>Accuracy of explanations</li>
            <li>Clarity and readability</li>
            <li>Technical correctness</li>
            <li>Completeness of coverage</li>
          </ul>
          <p class="table-hint">Judge model must be different from evaluated model.</p>
        </div>
        <div class="card">
          <h3>Traceability (TR) — 10%</h3>
          <p>Reference validation — are code references accurate?</p>
          <ul class="list-muted">
            <li>Variable names exist in source</li>
            <li>Paragraph names are valid</li>
            <li>Line numbers are accurate</li>
            <li>No hallucinated references</li>
          </ul>
          <p class="table-hint">Catches hallucinations and fabricated references.</p>
        </div>
      </div>
    </section>

    <section aria-labelledby="tiers">
      <h2 class="section-title" id="tiers">Task Complexity Tiers</h2>
      <p>Tasks are organized by COBOL program complexity:</p>
      <table>
        <thead>
          <tr>
            <th>Tier</th>
            <th>Name</th>
            <th>LOC Range</th>
            <th>Characteristics</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>T1</td>
            <td>Basic</td>
            <td>300-500</td>
            <td>Simple, linear programs with minimal branching</td>
          </tr>
          <tr>
            <td>T2</td>
            <td>Moderate</td>
            <td>500-1000</td>
            <td>PERFORM loops, file I/O operations</td>
          </tr>
          <tr>
            <td>T3</td>
            <td>Complex</td>
            <td>1000-2000</td>
            <td>External calls, complex business rules</td>
          </tr>
          <tr>
            <td>T4</td>
            <td>Enterprise</td>
            <td>2000+</td>
            <td>GO TO spaghetti, CICS/DB2 integration</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section aria-labelledby="ground-truth">
      <h2 class="section-title" id="ground-truth">Ground Truth Generation</h2>
      <p>Ground truth is automatically extracted from COBOL source code using static analysis:</p>
      <ul class="list-muted">
        <li><strong>Data Structures</strong> — WORKING-STORAGE, FILE SECTION, LINKAGE SECTION parsing</li>
        <li><strong>Control Flow</strong> — PERFORM, GO TO, paragraph/section analysis</li>
        <li><strong>Business Rules</strong> — IF/EVALUATE conditions, calculations, validations</li>
        <li><strong>Dependencies</strong> — CALL statements, COPY statements, file assignments</li>
        <li><strong>Error Handlers</strong> — ON ERROR, AT END, INVALID KEY patterns</li>
      </ul>
      <div class="callout">
        Ground truth is 95%+ automated. Only edge cases require human review.
      </div>
    </section>

    <section aria-labelledby="examples">
      <h2 class="section-title" id="examples">Scoring Example</h2>
      <div class="card">
        <h3>Sample Evaluation</h3>
        <div class="code-block">
          Component Scores:
          Structural Completeness (SC): 75%
          Behavioral Fidelity (BF): 80%
          Semantic Quality (SQ): 70%
          Traceability (TR): 60%

          LCB Score = (0.35 × 80) + (0.30 × 75) + (0.25 × 70) + (0.10 × 60)
          = 28 + 22.5 + 17.5 + 6
          = 74
        </div>
        <p><strong>Result: LCB Score 74/100</strong></p>
      </div>
    </section>

    <section aria-labelledby="faq">
      <h2 class="section-title" id="faq">FAQ</h2>
      <details class="faq">
        <summary>How is ground truth generated?</summary>
        <p>Ground truth is extracted automatically from COBOL source code using static analysis. The benchmark parses
          DATA DIVISION, PROCEDURE DIVISION, and analyzes control flow, business rules, and dependencies. This is 95%+
          automated with high confidence scores.</p>
      </details>
      <details class="faq">
        <summary>What if behavioral fidelity testing is unavailable?</summary>
        <p>BF testing requires Docker with GnuCOBOL. If unavailable, a placeholder score is used. Run with
          <code>--enable-execution</code> for full BF evaluation.</p>
      </details>
      <details class="faq">
        <summary>How does LLM-as-judge work?</summary>
        <p>A separate LLM (different from the model being evaluated) assesses documentation quality. This prevents
          self-evaluation bias. The judge model can be configured with <code>--judge-model</code>.</p>
      </details>
      <details class="faq">
        <summary>Can I reproduce the scores?</summary>
        <p>Yes. All evaluation is deterministic. Run
          <code>python -m legacycodebench evaluate --task-id &lt;id&gt; --submission &lt;path&gt;</code> to get
          identical scores.</p>
      </details>
    </section>
  </main>

  <footer>
    <div class="container" style="display:flex;flex-wrap:wrap;gap:1rem;justify-content:space-between;">
      <span>LegacyCodeBench · Kalmantic AI Labs + Hexaview Tech</span>
      <span>GitHub · <a href="https://github.com/kalmantic/legacycodebench" target="_blank"
          rel="noreferrer">kalmantic/legacycodebench</a></span>
      <span>Contact · <a href="mailto:nikita@kalmantic.com">nikita@kalmantic.com</a></span>
    </div>
  </footer>
</body>

</html>
